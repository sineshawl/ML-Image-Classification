{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_images/Tedy_Afro.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If it's a color image, you can access each channel\n",
    "# blue = img[50, 100, 0]\n",
    "# green = img[50, 100, 1]\n",
    "# red = img[50, 100, 2]\n",
    "\n",
    "img.shape # returns 3d numpy array (height, width, and channel (3 for rgb or 1 for gray scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('E:\\\\RoadMap\\\\ML Projects\\\\ML-Image-Classification\\\\opencv\\\\haarcascade\\\\haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('E:\\\\RoadMap\\\\ML Projects\\\\ML-Image-Classification\\\\opencv\\\\haarcascade\\\\haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "eyes = eye_cascade.detectMultiScale(img)\n",
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y,w,h) = faces[0]\n",
    "x,y,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2) #draw face\n",
    "plt.imshow(face_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        for (x, y, width, height) in faces:\n",
    "            face_image = cv2.rectangle(img, (x, y), (x+width, y+height), (255, 0, 0), 1)\n",
    "            face_region = img[y:y+height, x:x+width]\n",
    "            eyes = eye_cascade.detectMultiScale(face_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x, y, w, h) in faces:\n",
    "#     faces_image = cv2.rectangle(img,(x+y))\n",
    "for (x, y, width, height) in faces:\n",
    "    face_images = cv2.rectangle(img, (x,y), (x+width, y+height), (255, 0,0), 1) # (255, 0,0) <- is the color of rgb (blue), 2 <- the width of rectangle\n",
    "    only_face_color = img[y:y+height, x:x+width]\n",
    "    eyes = eye_cascade.detectMultiScale(only_face_color)\n",
    "    for (x_eye, y_eye, width_eye, height_eye) in eyes:\n",
    "        eyes_image = cv2.rectangle(only_face_color, (x_eye,y_eye), (x_eye+width_eye, y_eye+height_eye), (255, 0, 0), 1)\n",
    "plt.imshow(eyes_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns images if 2 eyes are visible\n",
    "def get_images_with_2_eyes(path):\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "        for (x, y, width, height) in faces:\n",
    "            face_image = cv2.rectangle(img, (x, y), (x+width, y+height), (255, 0, 0), 1)\n",
    "            face_region = img[y:y+height, x:x+width]\n",
    "            eyes = eye_cascade.detectMultiScale(face_region)\n",
    "            \n",
    "            if len(eyes) >= 2:\n",
    "                return face_region\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image = get_images_with_2_eyes('./test_images/Tedy_Afro.jpeg')\n",
    "plt.imshow(cropped_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img_dataset = './datasets/'\n",
    "path_to_cropped_img_datasets = './datasets/cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dir = []\n",
    "for dirs in os.scandir(path_to_img_dataset):\n",
    "    if dirs.is_dir():\n",
    "        img_dir.append(dirs.path)\n",
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "#shutil used to easly tree directory\n",
    "if os.path.exists(path_to_cropped_img_datasets):\n",
    "    shutil.rmtree(path_to_cropped_img_datasets)\n",
    "os.makedirs(path_to_cropped_img_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "\n",
    "for img_dir in img_dir:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    \n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        # print(entry)\n",
    "        print(entry)\n",
    "        roi_color = get_images_with_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cropped_img_datasets + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "                \n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name \n",
    "            \n",
    "            print(\"file_name:\",cropped_file_name)\n",
    "            print(\"celebrity_name\", celebrity_name)\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            print(cropped_file_path)\n",
    "\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet transform\n",
    "\n",
    "**Compression:** Wavelet transforms can be used to compress images, retaining essential features while reducing file size. <br>\n",
    "**Feature Extraction:** Key features can be extracted from images for tasks like classification and object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def toWavelet(img, mode='haar', level=1):\n",
    "    imgArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imgArray = cv2.cvtColor( imgArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imgArray =  np.float32(imgArray)   \n",
    "    imgArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imgArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imgArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imgArray_H *= 255;\n",
    "    imgArray_H =  np.uint8(imgArray_H)\n",
    "    return imgArray_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_har = toWavelet(cropped_image,'db1',5)\n",
    "plt.imshow(im_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names_dict = {}\n",
    "for img_dir in cropped_image_dirs:\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    file_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        file_list.append(entry.path)\n",
    "    celebrity_file_names_dict[celebrity_name] = file_list\n",
    "celebrity_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abdu Kiar': 0, 'Addis Alem Getaneh': 1, 'Tedy Afro': 2}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Wavelet and orginal image, these both can be usefull for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = toWavelet(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 4096)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping X\n",
    "X = np.array(X).reshape(len(X), 4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're gonna use SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The use of GridSearch to select best fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
